import pybullet as p
import pybullet_data
import numpy as np
import cv2
from stable_baselines3 import PPO

# --- 1. å®šæ•°ã¨ç’°å¢ƒè¨­å®š ---
URDF_FILE = "hopper.urdf"
MODEL_FILE = "ppo_hopper.zip"
VIDEO_FILE = "hopper_playback.mp4"

# éŒ²ç”»ç”¨ã®è¨­å®š
p.connect(p.DIRECT)
p.setAdditionalSearchPath(pybullet_data.getDataPath())
p.setGravity(0, 0, -9.81)
p.loadURDF("plane.urdf")
robot_id = p.loadURDF(URDF_FILE, [0, 0, 1.0])

# --- 2. ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
print(f"ğŸ“¦ ãƒ¢ãƒ‡ãƒ« {MODEL_FILE} ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
model = PPO.load(MODEL_FILE)

# --- 3. å‹•ç”»ä¿å­˜ã®è¨­å®š ---
width, height = 640, 480
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(VIDEO_FILE, fourcc, 30.0, (width, height))

# --- 4. å®Ÿè¡Œã¨éŒ²ç”» ---
# åˆæœŸçŠ¶æ…‹ã®å–å¾—
pos, _ = p.getBasePositionAndOrientation(robot_id)
joint_state = p.getJointState(robot_id, 0)
obs = np.array([pos[2], joint_state[0], joint_state[1]], dtype=np.float32)

print("ğŸ¬ å†ç”Ÿã¨éŒ²ç”»ã‚’é–‹å§‹ã—ã¾ã™...")
for i in range(500): # å°‘ã—é•·ã‚ã®15ç§’ç¨‹åº¦
    # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ã€Œæ¬¡ã€ã©ã†å‹•ãï¼Ÿã€ã¨èã
    action, _ = model.predict(obs, deterministic=True)
    
    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    p.setJointMotorControl2(robot_id, 0, p.TORQUE_CONTROL, force=action[0] * 50.0)
    p.stepSimulation()
    
    # æ¬¡ã®è¦³æ¸¬å€¤ã‚’å–å¾—
    pos, _ = p.getBasePositionAndOrientation(robot_id)
    joint_state = p.getJointState(robot_id, 0)
    obs = np.array([pos[2], joint_state[0], joint_state[1]], dtype=np.float32)

    # ã‚«ãƒ¡ãƒ©è¨­å®šï¼ˆãƒ­ãƒœãƒƒãƒˆã®å‹•ãã«åˆã‚ã›ã¦è¦–ç‚¹ã‚’å‹•ã‹ã™ï¼‰
    view_matrix = p.computeViewMatrix(
        cameraEyePosition=[2.5, 2.5, 1.5],
        cameraTargetPosition=[pos[0], pos[1], 0.5],
        cameraUpVector=[0, 0, 1]
    )
    proj_matrix = p.computeProjectionMatrixFOV(60, width/height, 0.1, 100.0)
    
    # æç”»
    (_, _, rgba, _, _) = p.getCameraImage(width, height, view_matrix, proj_matrix, renderer=p.ER_TINY_RENDERER)
    frame = np.array(rgba, dtype=np.uint8).reshape((height, width, 4))
    frame = cv2.cvtColor(frame[:, :, :3], cv2.COLOR_RGB2BGR)
    out.write(frame)

    # è»¢å€’ãƒªã‚»ãƒƒãƒˆå‡¦ç†
    if pos[2] < 0.3:
        p.resetBasePositionAndOrientation(robot_id, [0, 0, 1.0], [0, 0, 0, 1])

out.release()
p.disconnect()
print(f"âœ… å‹•ç”»ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {VIDEO_FILE}")