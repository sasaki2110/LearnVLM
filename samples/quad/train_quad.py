import gymnasium as gym
from gymnasium import spaces
import pybullet as p
import pybullet_data
import numpy as np
import os
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import SubprocVecEnv

# --- 1. å››è¶³Lå­—ãƒ­ãƒœãƒƒãƒˆ(URDF)ã®ç”Ÿæˆ ---
def create_quadruped_urdf():
    urdf_content = """
    <robot name="l_leg_quad">
      <link name="base">
        <visual><geometry><box size="0.4 0.4 0.1"/></geometry><material name="blue"><color rgba="0 0 1 1"/></material></visual>
        <collision><geometry><box size="0.4 0.4 0.1"/></geometry></collision>
        <inertial><mass value="2.0"/><inertia ixx="0.1" ixy="0" ixz="0" iyy="0.1" iyz="0" izz="0.1"/></inertial>
      </link>
    """
    # 4æœ¬ã®è¶³ã‚’ç”Ÿæˆ
    positions = [ [0.2, 0.2], [0.2, -0.2], [-0.2, 0.2], [-0.2, -0.2] ]
    for i, pos in enumerate(positions):
        urdf_content += f"""
      <link name="thigh_{i}">
        <visual><origin xyz="0 0 -0.1"/><geometry><box size="0.05 0.05 0.2"/></geometry><material name="red"><color rgba="1 0 0 1"/></material></visual>
        <collision><origin xyz="0 0 -0.1"/><geometry><box size="0.05 0.05 0.2"/></geometry></collision>
        <inertial>
            <origin xyz="0 0 -0.1"/>
            <mass value="0.2"/>
            <inertia ixx="0.001" ixy="0" ixz="0" iyy="0.001" iyz="0" izz="0.001"/>
        </inertial>
      </link>
      <link name="calf_{i}">
        <visual><origin xyz="0.1 0 0"/><geometry><box size="0.2 0.05 0.05"/></geometry><material name="green"><color rgba="0 1 0 1"/></material></visual>
        <collision><origin xyz="0.1 0 0"/><geometry><box size="0.2 0.05 0.05"/></geometry></collision>
        <inertial>
            <origin xyz="0.1 0 0"/>
            <mass value="0.2"/>
            <inertia ixx="0.001" ixy="0" ixz="0" iyy="0.001" iyz="0" izz="0.001"/>
        </inertial>
      </link>
      <joint name="hip_{i}" type="revolute">
        <parent link="base"/><child link="thigh_{i}"/><origin xyz="{pos[0]} {pos[1]} 0"/><axis xyz="0 1 0"/>
        <limit effort="100" lower="-1.5" upper="1.5" velocity="10"/>
      </joint>
      <joint name="knee_{i}" type="revolute">
        <parent link="thigh_{i}"/><child link="calf_{i}"/><origin xyz="0 0 -0.2"/><axis xyz="0 1 0"/>
        <limit effort="100" lower="-1.5" upper="1.5" velocity="10"/>
      </joint>
        """
    urdf_content += "</robot>"
    with open("quad.urdf", "w") as f: f.write(urdf_content)
    
# --- 2. ç’°å¢ƒã®å®šç¾© ---
class QuadrupedEnv(gym.Env):
    def __init__(self):
        super().__init__()
        self.client = p.connect(p.DIRECT)
        p.setAdditionalSearchPath(pybullet_data.getDataPath())
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: 8ã¤ã®é–¢ç¯€ã®ãƒˆãƒ«ã‚¯ (-1 to 1)
        self.action_space = spaces.Box(low=-1, high=1, shape=(8,), dtype=np.float32)
        # è¦³æ¸¬: èƒ´ä½“ã®é«˜ã•, Zé€Ÿåº¦, 8ã¤ã®é–¢ç¯€è§’åº¦ (è¨ˆ10å€‹)
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(10,), dtype=np.float32)

    def reset(self, seed=None, options=None):
        p.resetSimulation(physicsClientId=self.client)
        p.setGravity(0, 0, -9.81)
        p.loadURDF("plane.urdf")
        # ã¡ã‚‡ã†ã©ã„ã„é«˜ã•(0.3m)ã‹ã‚‰è½ã¨ã™
        self.robot_id = p.loadURDF("quad.urdf", [0, 0, 0.3])
        # æœ€åˆã¯å°‘ã—å¾…ã£ã¦å®‰å®šã•ã›ã‚‹ï¼ˆç‰©ç†æ¼”ç®—ã‚’ç©ºå›ã—ï¼‰
        for _ in range(20): p.stepSimulation()
        return self._get_obs(), {}

    def _get_obs(self):
        pos, _ = p.getBasePositionAndOrientation(self.robot_id)
        vel, _ = p.getBaseVelocity(self.robot_id)
        joint_states = [p.getJointState(self.robot_id, i)[0] for i in range(8)]
        return np.array([pos[2], vel[2]] + joint_states, dtype=np.float32)

    def step(self, action):
        # 8ã¤ã®é–¢ç¯€ã™ã¹ã¦ã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é©ç”¨
        for i in range(8):
            p.setJointMotorControl2(self.robot_id, i, p.TORQUE_CONTROL, force=action[i] * 100.0)
        
        p.stepSimulation()
        obs = self._get_obs()
        height, vz = obs[0], obs[1]
        
        # å ±é…¬: ã€Œé£›ã¶ã€ï¼é«˜ã•ã¸ã®å ±é…¬ ï¼‹ ä¸Šå‘ãã®é€Ÿåº¦ã¸ã®å¤§ããªãƒœãƒ¼ãƒŠã‚¹
        reward = height * 2.0
        if vz > 0.2: reward += vz * 10.0 # ã‚¸ãƒ£ãƒ³ãƒ—ã¸ã®å¼·ã„æ„æ¬²
        
        # èƒ´ä½“ãŒæ¥µç«¯ã«ä½ããªã£ãŸã‚‰ï¼ˆè»¢å€’ã—ãŸã‚‰ï¼‰çµ‚äº†
        terminated = height < 0.15
        return obs, reward, terminated, False, {}

# --- 3. å­¦ç¿’ï¼ˆä¸¦åˆ—å®Ÿè¡Œå¯¾å¿œï¼‰ ---
def make_env(rank):
    def _init(): return QuadrupedEnv()
    return _init

if __name__ == "__main__":
    create_quadruped_urdf()
    num_cpu = 4
    env = SubprocVecEnv([make_env(i) for i in range(num_cpu)])
    
    model = PPO("MlpPolicy", env, verbose=1, device="cuda")
    print("ğŸš€ å››è¶³ãƒ­ãƒœãƒƒãƒˆã®è·³èºå­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
    model.learn(total_timesteps=500000) # ã¾ãšã¯30åˆ†ã€œ1æ™‚é–“ç¨‹åº¦ã®50ä¸‡å›
    model.save("ppo_quad.zip")
    print("âœ… å­¦ç¿’å®Œäº†ï¼ ppo_quad.zip ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")