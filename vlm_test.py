import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from PIL import Image

# 1. ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æº–å‚™
# RTX 3060 Ti (8GB) ãªã‚‰ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ä½™è£•ã§å‹•ãã¾ã™
model_id = "vikhyatk/moondream2"
#revision = "2024-08-05"

print("ğŸš€ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...ï¼ˆåˆå›ã¯æ•°åˆ†ã‹ã‹ã‚Šã¾ã™ï¼‰")
model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    trust_remote_code=True, 
    #revision=revision,
    torch_dtype=torch.float16, # åŠç²¾åº¦ã§ãƒ¡ãƒ¢ãƒªç¯€ç´„
).to("cuda")

#tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)
tokenizer = AutoTokenizer.from_pretrained(model_id)
model.eval() # æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š

# 2. ç”»åƒã®èª­ã¿è¾¼ã¿ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
image_path = "test_image.jpg"
image = Image.open(image_path)
print(f"ğŸ“¸ ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {image_path}")

# VLMãŒç”»åƒã‚’ç†è§£ã™ã‚‹ãŸã‚ã®ã€Œè¦–è¦šç‰¹å¾´ã€ã‚’æŠ½å‡º
enc_image = model.encode_image(image)

# 3. è³ªå•ã—ã¦å›ç­”ã‚’å¾—ã‚‹
question = "Describe this image in one sentence."
#question = "Locate the bread roll in the image."
# ã€Œç‰©ä½“æ¤œå‡ºï¼ˆObject Detectionï¼‰ã€ã‚’æ˜ç¤ºçš„ã«æŒ‡ç¤ºã—ã¾ã™
#question = "Detect the bread roll in the image. Respond with a JSON object containing the coordinates."

#question = "Point out the bread roll with a bounding box."
print(f"â“ è³ªå•: {question}")

answer = model.answer_question(enc_image, question, tokenizer)
print(f"ğŸ’¡ å›ç­”: {answer}")

# ãƒ­ãƒœãƒƒãƒˆã‚¢ãƒ¼ãƒ ã®æ“ä½œã‚’æ„è­˜ã—ãŸè³ªå•ä¾‹
# question = "What objects are on the table?"
# question = "Where is the red object located in the image?"

